{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with TensorFlow\n",
    "\n",
    "Image classification is a common task for deep learning and neural networks.  The raw features coming in are the pixel values.  These are simple enough to deal with, but it is difficult to connect pixel values to determining whether an image is of a cat.  Older methods used a lot of clever filters, but the current best-of-breed algorithms simply throw a lot of linear algebra at the problem.\n",
    "\n",
    "In this project, we build a series of models to classify a series of images into one of ten classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and processing the data\n",
    "\n",
    "We consider the CIFAR-10 data set (https://www.cs.toronto.edu/~kriz/cifar.html). The data set is already converted to numpy arrays. For every practical purposes, we will have a set of PNG images. \n",
    "\n",
    "Therefore here we describe the process of the converting a set of PNG images to numpy array first. We download the same set of PNG images from \n",
    "https://www.kaggle.com/datasets/swaroopkml/cifar10-pngs-in-folders\n",
    "\n",
    "The directory contains sub-directories which contain the images of a particular class like Airplane, Bird, Cat ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The human readable names are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(os.walk(\"./archive/cifar10/cifar10/train/\"))[0][1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import pool\n",
    "Pool = pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dir = \"./archive/cifar10/cifar10/train/\"\n",
    "train_data = []\n",
    "\n",
    "# Loop through the image files in the directory\n",
    "for i in range(10):\n",
    "    for filename in os.listdir(image_dir+labels[i]):\n",
    "        image = Image.open(os.path.join(image_dir+labels[i], filename))\n",
    "\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        train_data.append(image_array)\n",
    "\n",
    "train_data = np.array(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./archive/cifar10/cifar10/test/\"\n",
    "test_data = []\n",
    "\n",
    "# Loop through the image files in the directory\n",
    "for i in range(10):\n",
    "    for filename in os.listdir(image_dir+labels[i]):\n",
    "        image = Image.open(os.path.join(image_dir+labels[i], filename))\n",
    "\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        test_data.append(image_array)\n",
    "\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.hstack([np.ones(5000)*i for i in range(10)])\n",
    "test_labels = np.hstack([np.ones(1000)*i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reshuffle the images randomly\n",
    "import random\n",
    "temp = list(zip(train_labels,train_data))\n",
    "random.shuffle(temp)\n",
    "train_labels,train_data = zip(*temp)\n",
    "train_labels,train_data = np.array(train_labels), np.array(train_data)\n",
    "\n",
    "temp = list(zip(test_labels,test_data))\n",
    "random.shuffle(temp)\n",
    "test_labels,test_data = zip(*temp)\n",
    "test_labels,test_data = np.array(test_labels), np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the images are properly imported in the numpy array. Check the 10286th image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fed984e4fd0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot.rcParams[\"axes.grid\"] = False  #  Remove the grid lines from the image.\n",
    "matplotlib.pyplot.imshow(train_data[10286,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[int(train_labels[10286])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(train_labels,10)\n",
    "y_test = tf.one_hot(test_labels,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(32, [5,5],strides=1, activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2, padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(32, [5,5],strides=1, activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2, padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(256,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "#model.add(tf.keras.layers.Dense(256,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 2.4985 - accuracy: 0.2103 - val_loss: 1.8658 - val_accuracy: 0.3255\n",
      "Epoch 2/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.7802 - accuracy: 0.3509 - val_loss: 1.5538 - val_accuracy: 0.4479\n",
      "Epoch 3/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.5603 - accuracy: 0.4364 - val_loss: 1.4838 - val_accuracy: 0.4605\n",
      "Epoch 4/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.4440 - accuracy: 0.4809 - val_loss: 1.3408 - val_accuracy: 0.5219\n",
      "Epoch 5/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.3545 - accuracy: 0.5211 - val_loss: 1.2679 - val_accuracy: 0.5482\n",
      "Epoch 6/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.2890 - accuracy: 0.5443 - val_loss: 1.2369 - val_accuracy: 0.5695\n",
      "Epoch 7/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.2256 - accuracy: 0.5705 - val_loss: 1.1829 - val_accuracy: 0.5908\n",
      "Epoch 8/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.1640 - accuracy: 0.5929 - val_loss: 1.1729 - val_accuracy: 0.5955\n",
      "Epoch 9/12\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1134 - accuracy: 0.6096 - val_loss: 1.1970 - val_accuracy: 0.5841\n",
      "Epoch 10/12\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 1.0751 - accuracy: 0.6261 - val_loss: 1.1121 - val_accuracy: 0.6207\n",
      "Epoch 11/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0360 - accuracy: 0.6414 - val_loss: 1.1945 - val_accuracy: 0.5996\n",
      "Epoch 12/12\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0109 - accuracy: 0.6495 - val_loss: 1.1212 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fedac0a01f0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,y_train, epochs=12, batch_size=50, validation_data=(test_data,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In transfer learning, we use a network trained on one data set to provide a starting point for the modeling of other data.  As we are trying to model color images, we should look for another network trained on color images. \n",
    "\n",
    "The following cell will load the model, omitting its classification layer (since we're not interested in classifying `ImageNet` images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96112376/96112376 [==============================] - 47s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# include_top=False will discard avg_pool before prediction layer\n",
    "inception = tf.keras.applications.inception_v3.InceptionV3(include_top=True, input_shape=(299, 299, 3))\n",
    "inception = tf.keras.Model([inception.input], [inception.layers[-2].output]) # manually discard prediction layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
